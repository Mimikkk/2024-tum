{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Teoria uczenia maszynowego - Projekt zaliczeniowy\n",
    "\n",
    "- Daniel Zdancewicz [indeks: 145317]\n",
    "\n",
    "## Temat:\n",
    "\n",
    "Wpływ dodawania szumu na trafność algorytmów uczenia. \n",
    "\n",
    "## Opis:\n",
    "\n",
    "Celem projektu jest zbadanie wpływu dodawania szumu na trafność algorytmów uczenia maszynowego.\n",
    "Szum jest dodawany do zbioru uczącego poprzez:\n",
    "\n",
    "- dodanie dodatkowych cech wejściowych z szumem.\n",
    "- zaszumienie istniejących cech.\n",
    "- zaszumienie wartości na wyjściu.\n",
    "\n",
    "## Plan realizacji i wybory projektowe:\n",
    "\n",
    "1. Wybór zbioru danych:\n",
    "    - zbiór danych \"Iris\" dostępny w bibliotece sklearn.datasets\n",
    "    - zbiór danych \"Wine\" dostępny w bibliotece sklearn.datasets\n",
    "2. Implementacja algorytmów uczenia maszynowego\n",
    "    - Wykorzystano algorytmy: SVM, KNN, Random Forest, oraz prostą sieć neuronową MLP\n",
    "    - Zaimplementowano funkcję, która zwraca trafność klasyfikacji dla zbioru danych\n",
    "3. Implementacja sposobów dodawania szumu\n",
    "    - Dodawanie szumu nowych cech wejściowych ze stałym szumem\n",
    "    - Dodawanie szumu nowych cech wejściowych ze skorelowanym szumem\n",
    "    - Dodawanie szumu do istniejących cech wejściowych ze stałym szumem\n",
    "    - Dodawanie szumu do istniejących cech wejściowych ze skorelowanym szumem\n",
    "    - Dodawanie szumu na wyjściu (losowe zmiany etykiet klas w części obiektów)\n",
    "4. Zbadanie wpływu dodawania szumu na trafność algorytmów uczenia maszynowego\n",
    "    - Zaimplementowano funkcję, która dodaje szum do zbioru danych, wewnątrz obrębu danych uczących, ale nie testowych.\n",
    "    - Zbadano wpływu dodania szumu na trafność klasyfikacji dla różnych algorytmów uczenia maszynowego\n",
    "5. Eksperymenty\n",
    "6. Wyniki\n",
    "7. Przedstawienie wniosków\n",
    "\n",
    "### Założenia o wynikach:\n",
    "- Dodanie szumu do zbioru danych prawdopodobnie obniży trafność klasyfikacji.\n",
    "- Dodanie szumu do wyjść bardzo prawdopodobnie obniży trafność klasyfikacji ze względu na niepoprawność klas.\n",
    "- Prawdopodobnie trafność klasyfikacji może zostać przywrócona poprzez zastosowanie odpowiednich technik regularyzacji, np PCA, L1, L2."
   ],
   "id": "60a2d2b2e17087fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "300142c07de8b23c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importy bibliotek i modułów",
   "id": "4a03636b6f81d008"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from analysis import visualize_correlation, visualize_metrics\n",
    "from experiments import summarize_results, run_experiments, create_model_descriptors\n",
    "from datasets.utils import load_datasets, create_noisy_datasets\n",
    "from datasets import DatasetNoise\n"
   ],
   "id": "58f75062dddd4232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wczytanie zbiorów danych",
   "id": "ff3ea9a9a1d2b21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "iris, wine = load_datasets()\n",
   "id": "e8264cfbac4b7584",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zbiór danych \"Iris\"\n",
    "\n",
    "Zbiór składający się z 150 próbek trzech gatunków irysów (Iris setosa, Iris virginica, Iris versicolor). \n",
    "\n",
    "Dla każdego irysa mamy 4 cechy: długość i szerokość płatków oraz długość i szerokość działki kielicha.\n",
    "\n",
    "Wszystkie te wartości są wartościami liczbowymi, założyłem dodatkową walidację wewnątrz klasy `IrisDataset` sprawdzającą czy wartości są liczbami.\n",
    "\n",
    "Zbiór ten jest dosyć mały i ma mało cech, służył mi jako zbiór do testów i weryfikacji poprawności implementacji."
   ],
   "id": "6f6a0620603b0d6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "iris.head()",
   "id": "72e8aff5c0ffe805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zbiór danych \"Wine\"\n",
    "\n",
    "Zbiór składający się z 178 próbek trzech gatunków win (klasy 0, 1, 2).\n",
    "\n",
    "Dla każdego wina mamy 13 cech:\n",
    "- Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline\n",
    "\n",
    "Wszystkie są również wartościami liczbowymi, i również założyłem dodatkową walidację wewnątrz klasy `WineDataset` sprawdzającą czy wartości są liczbami.\n",
    "\n",
    "Ten zbiór jest większy i ma więcej cech przez co pozwala na bardziej złożone eksperymenty."
   ],
   "id": "da95787d6608a13b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wine.head()",
   "id": "aa193a587bfeeb15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Algorytmy uczenia maszynowego\n",
    "\n",
    "Skorzystałem z gotowych implementacji algorytmów dostępnych w bibliotece `scikit-learn`.\n",
    "\n",
    "Wykorzystuje z niej algorytmy:\n",
    "- SVM, KNN, RandomForest oraz prostą sieć MLP.\n",
    "- KNN dałem w 3 wariantach z różną ilością sąsiadów ( 2, 3, 4 ).\n",
    "\n",
    "Implementacja algorytmów znajduje się w metodzie `create_model_descriptors`, która zwraca fabryki modeli z odpowiednimi labelkami.\n"
   ],
   "id": "77f4908db0517abb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "descriptors = create_model_descriptors()",
   "id": "2fffffaec0679028",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Algorytmy zaszumienia danych\n",
    "\n",
    "Do zaszumienia danych utworzyłem klasę `DatasetNoise` która pozwala na dodanie szumu do zbioru danych za pomocą 4 algorytmów. Podczas eksperymentów szumowanie danych odbywa się wewnątrz zbioru uczącego, ale nie testowego.\n"
   ],
   "id": "7958ae76e6f31238"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pomocnicze funkcje do wizualizacji różnic",
   "id": "ace3006c23bc5051"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from raport.display import render_difference, pick_first_column_id, pick_second_column_id",
   "id": "382c941b90aa9ee8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "column_id = pick_first_column_id(iris)\n",
    "clean = iris.head()"
   ],
   "id": "8687fa539b0807d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dodanie stałego szumu do kolumny\n",
    "\n",
    "Metody `add_static_noise/add_static_noises` - dodają szum do kolumny na podstawie różnicy maksymalnej i minimalnej wartości pomnożonej przez współczynnik skalowania."
   ],
   "id": "fd36d026dafd7db5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noisy_static = DatasetNoise(iris).add_static_noise(column_id, 0.1).build().head()\n",
    "\n",
    "render_difference(clean, noisy_static, column_id=column_id, title=\"Stały szum w skali 0.1\")\n"
   ],
   "id": "ee92902a2b1b5061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dodanie losowego szumu do kolumny\n",
    "\n",
    "Metody `add_random_noise/add_random_noises` - dodają losowy szum do kolumny na podstawie różnicy maksymalnej i minimalnej wartości pomnożonej przez współczynnik skalowania próbkowany z rand(scale_min, scale_max)."
   ],
   "id": "23f72b4893e4b40f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noisy_random = DatasetNoise(iris).add_random_noise(column_id, (0.0, 0.2)).build().head()\n",
    "\n",
    "render_difference(clean, noisy_random, column_id=column_id, title=\"Losowy szum w skali (0.0, 0.2)\")"
   ],
   "id": "27dfb5c93a09a5f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dodanie stałego skorelowanego szumu do kolumny\n",
    "\n",
    "Metody `add_static_correlated_noise/add_static_correlated_noises` - dodają skorelowany szum do kolumny na podstawie różnicy maksymalnej i minimalnej wartości pomnożonej przez normy wskazanej kolumny."
   ],
   "id": "a90d0545261dd72b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "first_column_id = pick_first_column_id(iris)\n",
    "second_column_id = pick_second_column_id(iris)\n",
    "column_ids = [first_column_id, second_column_id]\n",
    "\n",
    "noisy_correlated_static = (\n",
    "  DatasetNoise(iris)\n",
    "  .add_static_correlated_noise(first_column_id, second_column_id)\n",
    "  .build()\n",
    "  .head()\n",
    ")\n",
    "\n",
    "render_difference(clean, noisy_correlated_static, column_ids=column_ids, title=\"Stały skorelowany szum\")"
   ],
   "id": "917cb8c9629e7378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "82282c89d91991bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dodanie losowego skorelowanego szumu do kolumny\n",
    "\n",
    "Metody `add_random_correlated_noise/add_random_correlated_noises` - dodają skorelowany szum do kolumny na podstawie różnicy maksymalnej i minimalnej wartości pomnożonej przez normy wskazanej kolumny próbkowany z rand(scale_min, scale_max).\n"
   ],
   "id": "484d9b1b007cf99a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noisy_correlated_random = (\n",
    "  DatasetNoise(iris)\n",
    "  .add_random_correlated_noise(first_column_id, second_column_id, (0.0, 0.2))\n",
    "  .build()\n",
    "  .head()\n",
    ")\n",
    "\n",
    "render_difference(clean, noisy_correlated_random, column_ids=column_ids,\n",
    "                  title=\"Losowy skorelowany szum w skali (0.0, 0.2)\")"
   ],
   "id": "b34ddd35b66785ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dodanie szumu do wyjścia\n",
    "\n",
    "Metoda `shuffle` - Miesza wskazany procent etykiet klas w zbiorze danych w obrębie wskazanej kolumny."
   ],
   "id": "9ac813f43a116c7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pick_last_column_id(dataset):\n",
    "  return dataset.columns[-1]\n",
    "\n",
    "target_column_id = pick_last_column_id(iris)\n",
    "\n",
    "noisy_output = DatasetNoise(iris).shuffle(target_column_id, percentage=1.0).build().head()\n",
    "\n",
    "render_difference(clean, noisy_output, column_id=target_column_id, title=\"Szum na wyjściu po przemieszaniu etykiet\")"
   ],
   "id": "f16eb639127b3a11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Eksperymenty\n",
    "\n",
    "Eksperymenty polegały na zbadaniu wpływu dodawania szumu na różnych metrykach dla różnych algorytmów uczenia maszynowego.\n",
    "\n",
    "Implementacja przebiegu eksperymentu jest opisany wewnątrz metody `run_experiments`, a sposób jego podsumowania wewnątrz metody `summarize_results`. Podobnie metody wizualizacji są wewnątrz metody `visualize_metrics` oraz `visualize_correlation`.\n",
    "\n",
    "Sposób wytworzenia zaszumionych zbiorów danych znajduje się w metodzie `create_noisy_datasets`, która przechodzi przez parametryzację tworzonych szumów. Parametry to:\n",
    "- `dataset` - zbiór danych do zaszumienia\n",
    "  - `iris` - zbiór danych \"Iris\"\n",
    "  - `wine` - zbiór danych \"Wine\"\n",
    "- `use_create_noise_input` - czy użyć nowych kolumn szumu na wejściu\n",
    "  - Tak/Nie\n",
    "- `random_input_type` -  rodzaj szumu na wejściu\n",
    "  - `static` - stały szum\n",
    "  - `random` - losowy szum\n",
    "  - `corr-static` - stały skorelowany szum\n",
    "  - `corr-random` - losowy skorelowany szum ( random column )\n",
    "- `random_input_scale` - skalowanie szumu na wejściu ( random column )\n",
    "  - (0.1, 0.25, 0.75) \n",
    "- `random_input_count` - ilość nowych zaszumionych kolumn na wejściu\n",
    "  - (1, 2, 3)\n",
    "- `use_modify_noise_input` - czy użyć modyfikowanych kolumn szumem na wejściu ( random )\n",
    "  - Tak/Nie\n",
    "- `modified_input_type` -  rodzaj szumu na wejściu\n",
    "  - `static` - stały szum\n",
    "  - `random` - losowy szum\n",
    "  - `corr-static` - stały skorelowany szum\n",
    "  - `corr-random` - losowy skorelowany szum\n",
    "- `modified_input_scale` - skalowanie szumu na wejściu\n",
    "  - (0.1, 0.25, 0.75) \n",
    "- `use_noise_output` - czy użyć szumu na wyjściu\n",
    "  - Tak/Nie\n",
    "- `random_output_scale` - skala przemieszania etykiet na wyjściu\n",
    "  - (0.1, 0.25, 0.75) \n",
    "\n",
    "Przy wyborze kolumn do korelacji, nie mogą być powtórzone, ani target.\n",
    "\n",
    "Niektóre kombinacje są powtórzeniami, ze względu na to, że niektóre parametry nie występują w parach, te pary są pomijane na podstawie unikalności ich klucza, który można zobaczyć wewnątrz metody `create_noisy_datasets`.\n",
    "W efekcie jest 952 kombinacji eksperymentów.\n",
    "\n",
    "Uruchomienie eksperymentów dzieje się poprzez wywołanie metody `run_experiment` na wszystkich parach dostępnych modeli i utworzonych zbiorach w ramach modyfikacji danych. "
   ],
   "id": "b94565087bbf5ff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RunCount = 50\n",
    "\n",
    "iris, wine = load_datasets()\n",
    "datasets = create_noisy_datasets(iris, wine)\n",
    "\n",
    "results = run_experiments(datasets, descriptors, run_count=RunCount)"
   ],
   "id": "85f7385e52aa6f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wyniki\n",
    "\n",
    "Wyniki są monadem agregrującym wyniki z eksperymentów. Zawiera on informacje o wynikach dla każdego modelu, dla każdego zbioru danych, dla każdego rodzaju szumu.\n",
    "- Wynik składa się z metryk: accuracy, precision, recall, confusion, które zawierają odpowiednie wartości dla każdego modelu.\n",
    "- W poszczególnych metrykach znajdują się wyniki dla każdego eksperymentu, ich medianie, średniej, odchylenia standardowego oraz minimalnej i maksymalnej wartości."
   ],
   "id": "caa5fd461de15180"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary = summarize_results(results)\n",
   "id": "229df46d697cf77d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasets = [*{key.split(':')[0].split('_', 1)[0] for key in summary}]\n",
    "models = [*{key.split(':')[-1] for key in summary}]\n"
   ],
   "id": "c6f8d32d59f7208a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wizualizacja wyników\n",
    "\n",
    "Wizualizacja wyników polega na przedstawieniu wyników w postaci tabeli oraz wykresów. Implementacja wewnątrz metody `visualize_metrics`.\n",
    "\n",
    "Do raportu przedstawiam tylko metrykę `accuracy` i `confusion` z powodu ograniczeń miejsca. W metodzie `visualize_metrics`. wystarczyłoby zmienić wartość `metric` na inną wartość z listy. z powodu czytelności zamieszczam wykresy z tylko częścią (6 wyników i model bez szumu)."
   ],
   "id": "30808704a0fd70f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"Datasets: {datasets}\")\n",
    "for dataset in datasets:\n",
    "  print(f\"  - Dataset: {dataset}\")\n",
    "  for model in models:\n",
    "    print(f\"    - Model: {model}\")\n",
    "    partial_summary = {key: value for key, value in summary.items() if key.startswith(dataset) if key.endswith(model)}\n",
    "    partial_summary.pop(f\"{dataset}:{model}\")\n",
    "\n",
    "    partial_summary_keys = np.random.choice(list(partial_summary.keys()), 6, replace=False)\n",
    "\n",
    "    partial_summary = \\\n",
    "      {\n",
    "        f\"{dataset}:{model}\": summary[f\"{dataset}:{model}\"]\n",
    "      } | {\n",
    "        key: summary[key] for key in partial_summary_keys\n",
    "      }\n",
    "    visualize_metrics(partial_summary)\n"
   ],
   "id": "19b5040f9b45ade3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1831b5ced53e8c27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Na części zestawu danych można zauważyć, że wraz ze zmianą parametryzacji zmienia się jakość klasyfikacji. Widać, również że dodanie szumu obniża jakość klasyfikacji, ale nie zawsze. W niektórych przypadkach dodanie szumu pozostawia jakość klasyfikacji na zbliżonym poziomie, lub czasami większy.",
   "id": "8b5d9374473cecd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_metrics(summary)",
   "id": "da9af746f65f9d52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Na pełnym zestawie danych ewidentnie można zauważyć, że wraz ze zmianą parametryzacji zmienia się jakość klasyfikacji. Widać, że dodanie szumu obniża jakość klasyfikacji, ale nie zawsze. W niektórych przypadkach dodanie szumu pozostawia jakość klasyfikacji na zbliżonym poziomie. Najwyższy spadek na pełnym wykresie jest dla zaszumiania wyjścia.",
   "id": "989102aa506b498c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Testy korelacji między cechami, a wynikami\n",
    "\n",
    "Na podstawie wyników, dokonałem, testów, na których można zobaczyć jaki wpływ ma modyfikacja poszczególnych cech na wynik klasyfikacji. Implementacja wewnątrz metody `visualize_correlation`. z powodu ograniczeń tak samo jak wcześniej ograniczyłem się do 6 wyników i głównego, czasami test jest znaczący, a czasami nie, zależnie od modelu i zestawu danych. Jednak samo powstawanie znaczących testów jest ciekawe. "
   ],
   "id": "5783359b2133bc38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"Datasets: {datasets}\")\n",
    "for dataset in datasets:\n",
    "  print(f\"  - Dataset: {dataset}\")\n",
    "  for model in models:\n",
    "    print(f\"    - Model: {model}\")\n",
    "    partial_summary = {key: value for key, value in summary.items() if key.startswith(dataset) if key.endswith(model)}\n",
    "    partial_summary.pop(f\"{dataset}:{model}\")\n",
    "\n",
    "    partial_summary_keys = np.random.choice(list(partial_summary.keys()), 6, replace=False)\n",
    "\n",
    "    partial_summary = \\\n",
    "      {\n",
    "        f\"{dataset}:{model}\": summary[f\"{dataset}:{model}\"]\n",
    "      } | {\n",
    "        key: summary[key] for key in partial_summary_keys\n",
    "      }\n",
    "    visualize_correlation(partial_summary)\n"
   ],
   "id": "bcbda46d1a24fc88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wnioski\n",
    "\n",
    "Po analizę korelacji między cechami a wynikami i z tego widać, że w części przypadków dodanie szumu obniża trafność klasyfikacji i faktycznie wpływa na jakość wytrenowanego modelu. \n",
    "\n",
    "W niektórych przypadkach dodanie szumu nie wpływa na jakość klasyfikacji, a w niektórych przypadkach nawet ją poprawia, co może wynikać z faktu, że dodanie szumu pozwala na lepsze generalizowanie modelu.\n",
    "\n",
    "Również widać, że zaszumianie klasy wyjścia znacząco obniża jakość klasyfikacji, nie spodziewałem się, że aż tak silnie, im więcej etykiet jest przemieszanych tym gorsza jest jakość klasyfikacji, co jest zrozumiałe, ponieważ model nie jest w stanie się nauczyć poprawnie klasyfikować obiektów. Pomimo tego, klasyfikacja jest mniej więcej zachowana do 25% wymieszanych etykiet.\n",
    "\n",
    "Niemniej, wnioski potwierdzają moje założenia, że dodanie szumu obniża jakość klasyfikacji, ale nie zawsze, a szum na wyjściu obniża znacząco jakość klasyfikacji.\n",
    "\n",
    "Jako dalsze kroki, można by było zastosować techniki regularyzacji, ( te PCA, L1, L2 ), które mogą wpłynąć dosyć pozytywnie na ususwanie zaszumień, a także zastosować bardziej zaawansowane techniki szumienia danych, które mogą pomóc w lepszym generalizowaniu modelu.\n"
   ],
   "id": "2f3c89b9406cb680"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
